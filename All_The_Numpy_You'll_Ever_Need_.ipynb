{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by importing numpy!"
      ],
      "metadata": {
        "id": "jj2kf4U2sSpm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ypuEQ6qfsNGK"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing numpy as np is a common convention but I won't judge you if you picked your favorite short string!"
      ],
      "metadata": {
        "id": "QpZ-Wm78sZoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating numpy arrays\n",
        "\n",
        "Let's start with some basics. np.array() creates numpy arrays from python lists."
      ],
      "metadata": {
        "id": "_fpJP7SEtfcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "print(f'{x = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD1j3G2WsZTY",
        "outputId": "997bb804-c077-4845-c3f6-48b872068d92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [2, 3],\n",
            "       [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a few more common ways of creating numpy arrays:"
      ],
      "metadata": {
        "id": "4Mm-7hTMAymL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(2, 10, 2)\n",
        "print(f'{x = }')\n",
        "\n",
        "x = np.zeros((3, 2))\n",
        "print(f'{x = }')\n",
        "\n",
        "x = np.ones((3, 2))\n",
        "print(f'{x = }')\n",
        "\n",
        "x = np.tril(np.ones((3,3)))  # tril => lower triangle, useful for creating causal masks!\n",
        "print(f'{x = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3mYctp4Aw_d",
        "outputId": "ec2daad7-8c0b-4444-c021-1becf0e77e91"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([2, 4, 6, 8])\n",
            "x = array([[0., 0.],\n",
            "       [0., 0.],\n",
            "       [0., 0.]])\n",
            "x = array([[1., 1.],\n",
            "       [1., 1.],\n",
            "       [1., 1.]])\n",
            "x = array([[1., 0., 0.],\n",
            "       [1., 1., 0.],\n",
            "       [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The np.random package can be used to create arrays with random numbers:"
      ],
      "metadata": {
        "id": "Hi6LWD8z_jY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random arrays of shape = (3, 2)\n",
        "x = np.random.rand(3, 2)  # random samples from a uniform distribution over [0, 1)\n",
        "print(f'{x = }')\n",
        "\n",
        "x = np.random.randn(3, 2)  # random samples from the \"standard normal\" distribution\n",
        "print(f'{x = }')\n",
        "\n",
        "x = np.random.randint(low=3, high=10, size=(3,2))  # random sampled in the int range [low, high)\n",
        "print(f'{x = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnpezcY6_hrO",
        "outputId": "646229b3-4248-4fac-ed5e-33861721382f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[0.71247287, 0.42528162],\n",
            "       [0.08128043, 0.38892688],\n",
            "       [0.63015336, 0.47903512]])\n",
            "x = array([[ 0.41907239,  0.23361579],\n",
            "       [-0.41244341, -0.92222489],\n",
            "       [-0.65285907,  0.1902672 ]])\n",
            "x = array([[4, 7],\n",
            "       [4, 3],\n",
            "       [4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dtype and shape\n",
        "Commonly useful properties of a numpy array are its shape and dtype."
      ],
      "metadata": {
        "id": "7G_geMkYtKM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{x.shape = }')\n",
        "print(f'{x.dtype = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0knzIEFtIkR",
        "outputId": "d1551f8c-4e71-4e22-93f7-9aa2b48efe58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape = (3, 2)\n",
            "x.dtype = dtype('int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape and dtype of a numpy array can be changed to other compatible values, for instance:"
      ],
      "metadata": {
        "id": "KSqyBCO8yA3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "print(f'{x.shape = }')\n",
        "print(f'{x.dtype = }')\n",
        "\n",
        "# reshape\n",
        "x_23 = np.reshape(x, [2, 3])\n",
        "x_6 = x.reshape((-1, 1))  # numpy infers the value of -1, provided it's inferable.\n",
        "print(f'{x_23 = }, {x_23.shape = }')\n",
        "print(f'{x_6 = }, {x_6.shape = }')\n",
        "\n",
        "# change dtypes\n",
        "x_bool = np.array([True, False, False, True])\n",
        "x_int = x_bool.astype(np.int32)\n",
        "print(f'{x_int = }, {x_int.dtype = }')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3aQqri8yAf9",
        "outputId": "d3ec11e1-09b5-4947-a947-2e41fe1dd1d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape = (3, 2)\n",
            "x.dtype = dtype('int64')\n",
            "x_23 = array([[1, 2, 2],\n",
            "       [3, 3, 4]]), x_23.shape = (2, 3)\n",
            "x_6 = array([[1],\n",
            "       [2],\n",
            "       [2],\n",
            "       [3],\n",
            "       [3],\n",
            "       [4]]), x_6.shape = (6, 1)\n",
            "x_int = array([1, 0, 0, 1], dtype=int32), x_int.dtype = dtype('int32')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "nle35-5WtckE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a few examples:"
      ],
      "metadata": {
        "id": "sBg7di1duvPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "print(f'{x = }')\n",
        "\n",
        "# access an element, python-style\n",
        "print(f'{x[0][1] = }')\n",
        "\n",
        "# access an element, numpy-style\n",
        "print(f'{x[0, 1] = }')\n",
        "\n",
        "# access a row\n",
        "print(f'{x[0] = }')\n",
        "\n",
        "# access a column\n",
        "print(f'{x[:, 0] = }')  # : means all the values from that axis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcSe0MldtdUZ",
        "outputId": "81ea08e2-2f22-4961-fee7-7c52e768a41a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [2, 3],\n",
            "       [3, 4]])\n",
            "x[0][1] = np.int64(2)\n",
            "x[0, 1] = np.int64(2)\n",
            "x[0] = array([1, 2])\n",
            "x[:, 0] = array([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though python-style access and numpy-style access look identical, they can be deceptively different. Let's look at an example:"
      ],
      "metadata": {
        "id": "09HYEe5Lv25y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{x[:, 0] = }')\n",
        "print(f'{x[:][0] = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u__p7unvqvR",
        "outputId": "519623e3-9161-4136-9a54-0f5092b44adb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x[:, 0] = array([1, 2, 3])\n",
            "x[:][0] = array([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x[:, 0]` returned the first column, but `x[:][0]` returned the first row. What happened here?\n",
        "\n",
        "`x[:][0]` creates a chain of two accesses: it first evaluates `x[:]`, which returns all of x, then evaluates res[0], which takes element 0 of the original array, hence returning the first row of the array. This behavior is consistent in python (`[[1, 2], [2, 3]][:][0] == [1, 2]`)\n",
        "\n",
        "`x[:, 0]` indexes both axes at once: all rows, column 0, and returns the first column."
      ],
      "metadata": {
        "id": "QKPKZiTmvqZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numpy arrays are mutable:"
      ],
      "metadata": {
        "id": "nvo6z-mMs74J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4]])\n",
        "print(f'{x = }')\n",
        "\n",
        "print(\"# edit an element\")\n",
        "x[0][1] = -1\n",
        "print(f'{x = }')\n",
        "\n",
        "print(\"# edit a row\")\n",
        "x[0] = [-1, -2]\n",
        "print(f'{x = }')\n",
        "\n",
        "print(\"# edit a column\")\n",
        "x[:, 0] = [-1, -2, -3]\n",
        "print(f'{x = }')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpX2TqQGs7Ke",
        "outputId": "ad2b8ab7-5fe0-4a9e-deaf-c73c81ccdfef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [2, 3],\n",
            "       [3, 4]])\n",
            "# edit an element\n",
            "x = array([[ 1, -1],\n",
            "       [ 2,  3],\n",
            "       [ 3,  4]])\n",
            "# edit a row\n",
            "x = array([[-1, -2],\n",
            "       [ 2,  3],\n",
            "       [ 3,  4]])\n",
            "# edit a column\n",
            "x = array([[-1, -2],\n",
            "       [-2,  3],\n",
            "       [-3,  4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a few more examples of using `:` and `::` to access numpy arrays"
      ],
      "metadata": {
        "id": "e2W-ibl80m1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
        "print(f'{x = }')\n",
        "\n",
        "# access first 2 rows\n",
        "print(f'{x[:2] = }')\n",
        "\n",
        "# start at 1-th row, end at 4-th row\n",
        "print(f'{x[1:4] = }')\n",
        "\n",
        "# start at 1-th row, end at 4-th row, access every 2nd row\n",
        "print(f'{x[1:4:2] = }')\n",
        "\n",
        "# start at 0-th row, end at 4-th row, access every 2nd row\n",
        "print(f'{x[:4:2] = }')\n",
        "\n",
        "# start at 1-th row, end at the end, access every 2nd row\n",
        "print(f'{x[1::2] = }')\n",
        "\n",
        "# start at beginning, end at the end, access every 2nd row\n",
        "print(f'{x[::2] = }')\n",
        "\n",
        "# start at beginning, end at the end, access every -1-th row (in reverse)\n",
        "print(f'{x[::-1] = }')\n",
        "\n",
        "# start at beginning, end at the end, access every -1-th row and 0-th col\n",
        "print(f'{x[::-1, 0] = }')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tktmf14JzqQw",
        "outputId": "c7e22648-4510-4ee8-d3ce-bbb3153eb164"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [2, 3],\n",
            "       [3, 4],\n",
            "       [4, 5],\n",
            "       [5, 6],\n",
            "       [6, 7]])\n",
            "x[:2] = array([[1, 2],\n",
            "       [2, 3]])\n",
            "x[1:4] = array([[2, 3],\n",
            "       [3, 4],\n",
            "       [4, 5]])\n",
            "x[1:4:2] = array([[2, 3],\n",
            "       [4, 5]])\n",
            "x[:4:2] = array([[1, 2],\n",
            "       [3, 4]])\n",
            "x[1::2] = array([[2, 3],\n",
            "       [4, 5],\n",
            "       [6, 7]])\n",
            "x[::2] = array([[1, 2],\n",
            "       [3, 4],\n",
            "       [5, 6]])\n",
            "x[::-1] = array([[6, 7],\n",
            "       [5, 6],\n",
            "       [4, 5],\n",
            "       [3, 4],\n",
            "       [2, 3],\n",
            "       [1, 2]])\n",
            "x[::-1, 0] = array([6, 5, 4, 3, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike python, numpy arrays can also be indexed using integer lists:"
      ],
      "metadata": {
        "id": "WCNR1Z5an8Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
        "print(f'{x = }')\n",
        "\n",
        "print(f'{x[[1, 3, 1]] = }')\n",
        "print(f'{x[np.array([1, 3, 5]), np.array([0, 1, 0])] = }')  # x[1, 0], x[3, 1], x[5, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5KGSNq0n13F",
        "outputId": "bbb82035-4818-47dc-b12d-60c14c07d80b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [2, 3],\n",
            "       [3, 4],\n",
            "       [4, 5],\n",
            "       [5, 6],\n",
            "       [6, 7]])\n",
            "x[[1, 3, 1]] = array([[2, 3],\n",
            "       [4, 5],\n",
            "       [2, 3]])\n",
            "x[np.array([1, 3, 5]), np.array([0, 1, 0])] = array([2, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be used to reorder arrays; the example below reorders array x in the decreasing order of array y. This is useful for instance when sampling from a language model, where the vocab ids have to be ordered by the probabilities generated by the model)\n",
        "\n"
      ],
      "metadata": {
        "id": "k37dSvhVrpBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.permutation(5)\n",
        "y = np.random.randn(5)\n",
        "sorted_indices = np.argsort(x)\n",
        "reverse_sorted_indices = sorted_indices[::-1]\n",
        "\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "print(f'{reverse_sorted_indices = }')\n",
        "print(f'{y[reverse_sorted_indices] = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCOkii1drPp6",
        "outputId": "aa166893-21f9-4ba0-cf6c-13b354f3574d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([1, 3, 0, 4, 2])\n",
            "y = array([-0.94947826, -0.42810292,  0.49767165,  0.93196266,  0.20026202])\n",
            "reverse_sorted_indices = array([3, 1, 4, 0, 2])\n",
            "y[reverse_sorted_indices] = array([ 0.93196266, -0.42810292,  0.20026202, -0.94947826,  0.49767165])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also filter numpy arrays using bool lists or arrays for indexing:"
      ],
      "metadata": {
        "id": "fIXdK7CtoO9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
        "mask = np.array([True, False, False, True, True, False])\n",
        "print(f'{x = }')\n",
        "print(f'{mask = }')\n",
        "\n",
        "print(f'{x[mask] = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CUyb6VgoOiC",
        "outputId": "47481fc1-dca1-4fa4-9840-75ec538db27b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [2, 3],\n",
            "       [3, 4],\n",
            "       [4, 5],\n",
            "       [5, 6],\n",
            "       [6, 7]])\n",
            "mask = array([ True, False, False,  True,  True, False])\n",
            "x[mask] = array([[1, 2],\n",
            "       [4, 5],\n",
            "       [5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can be used to filter numpy arrays based on the values of (the same or other) numpy arrays, e.g. selecting model outputs belonging to a particular class of examples."
      ],
      "metadata": {
        "id": "SRMs11gZqrxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(-5, 5)\n",
        "y = np.random.randn(x.shape[0])\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "print(f'{y[x > 2] = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhib1fsIqe93",
        "outputId": "135b6745-fe4e-424e-df72-70055b8561cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([-5, -4, -3, -2, -1,  0,  1,  2,  3,  4])\n",
            "y = array([ 0.81478051,  0.56263881, -0.26024234,  1.98922655, -0.67673687,\n",
            "        0.31322671, -0.20885959, -0.33416936,  0.75858371,  0.12762243])\n",
            "y[x > 2] = array([0.75858371, 0.12762243])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick reminder that numpy arrays are mutable, so all access patterns above can be used to set the values of the array at those indices (in contrast, jax arrays are immutable)."
      ],
      "metadata": {
        "id": "RrbtX1x90tES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting\n",
        "\n",
        "Let's look at a few simple operations."
      ],
      "metadata": {
        "id": "611RY55e2Abh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "y = np.array([[2, 3], [4, 5], [6, 7]])\n",
        "\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "print(f'{x + y = }')\n",
        "print(f'{x - y = }')\n",
        "print(f'{x * y = }')\n",
        "print(f'{x / y = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV2IyqZk_c4e",
        "outputId": "78478e8e-74fc-414f-883c-851e58ee0746"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2],\n",
            "       [3, 4],\n",
            "       [5, 6]])\n",
            "y = array([[2, 3],\n",
            "       [4, 5],\n",
            "       [6, 7]])\n",
            "x + y = array([[ 3,  5],\n",
            "       [ 7,  9],\n",
            "       [11, 13]])\n",
            "x - y = array([[-1, -1],\n",
            "       [-1, -1],\n",
            "       [-1, -1]])\n",
            "x * y = array([[ 2,  6],\n",
            "       [12, 20],\n",
            "       [30, 42]])\n",
            "x / y = array([[0.5       , 0.66666667],\n",
            "       [0.75      , 0.8       ],\n",
            "       [0.83333333, 0.85714286]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the above operations are element-wise (the operation is applied on each x[i, j] and y[i, j] pair) and easy to understand. What if shapes aren't the same?\n",
        "\n",
        "Numpy tries to broadcast the shape of the smaller array across the shape of the larger array to make them compatible. Here's the simplest example:"
      ],
      "metadata": {
        "id": "lzIyV2FRB-_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2,3], [2,3,4], [4,5,6]])\n",
        "print(f'{x = }')\n",
        "print(f'{1 + x = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sSMawW7wMYx",
        "outputId": "19a155a2-7bdd-42a1-f051-a37cda8a89c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 2, 3],\n",
            "       [2, 3, 4],\n",
            "       [4, 5, 6]])\n",
            "1 + x = array([[2, 3, 4],\n",
            "       [3, 4, 5],\n",
            "       [5, 6, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, the scalar 1 gets broadcasted to the shape of x, i.e. (3, 3) so it can be added to x. Let's look at a less simple example:"
      ],
      "metadata": {
        "id": "XVIkJjwgwjYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3])\n",
        "y = np.array([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\n",
        "print(f'{x = }, {x.shape = }')\n",
        "print(f'{y = }, {y.shape = }')\n",
        "print(f'{x + y = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DauQWlKfB-dI",
        "outputId": "7c3b0eb6-0931-4272-b0d1-de761d9f837a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([1, 2, 3]), x.shape = (3,)\n",
            "y = array([[1, 2, 3],\n",
            "       [2, 3, 4],\n",
            "       [4, 5, 6]]), y.shape = (3, 3)\n",
            "x + y = array([[2, 4, 6],\n",
            "       [3, 5, 7],\n",
            "       [5, 7, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X was replicated across axis = 0, so the above operation was equivalent to `[[1, 2, 3], [2, 3, 4], [4, 5, 6]] + [[1, 2, 3], [1, 2, 3], [1, 2, 3]]`. What if we wanted to replcate X across axis = 0, and perform the equivalent of `[[1, 2, 3], [2, 3, 4], [4, 5, 6]] + [[1, 1, 1], [2, 2, 2], [3, 3, 3]]`?\n",
        "\n",
        "We can do this without making needless copies of the smaller array, by adding new dimensions to the array. Here are 3 equivalent ways to do this:"
      ],
      "metadata": {
        "id": "e3GVXj8w1YTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3])\n",
        "print(f'{x = }, {x.shape = }')\n",
        "\n",
        "print()\n",
        "\n",
        "print(f'{x[None, :] = }, {x[None, :].shape = }')\n",
        "print(f'{x[np.newaxis, :] = }, {x[np.newaxis, :].shape = }')\n",
        "print(f'{np.expand_dims(x, axis=0) = }, {np.expand_dims(x, axis=0).shape = }')\n",
        "\n",
        "print()\n",
        "\n",
        "print(f'{x[:, None] = }, {x[:, None].shape = }')\n",
        "print(f'{x[:, np.newaxis] = }, {x[:, np.newaxis].shape = }')\n",
        "print(f'{np.expand_dims(x, axis=1) = }, {np.expand_dims(x, axis=1).shape = }')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohbdQMDLzV25",
        "outputId": "40d96c0c-c2ff-4ee2-bb10-63c043464a78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([1, 2, 3]), x.shape = (3,)\n",
            "\n",
            "x[None, :] = array([[1, 2, 3]]), x[None, :].shape = (1, 3)\n",
            "x[np.newaxis, :] = array([[1, 2, 3]]), x[np.newaxis, :].shape = (1, 3)\n",
            "np.expand_dims(x, axis=0) = array([[1, 2, 3]]), np.expand_dims(x, axis=0).shape = (1, 3)\n",
            "\n",
            "x[:, None] = array([[1],\n",
            "       [2],\n",
            "       [3]]), x[:, None].shape = (3, 1)\n",
            "x[:, np.newaxis] = array([[1],\n",
            "       [2],\n",
            "       [3]]), x[:, np.newaxis].shape = (3, 1)\n",
            "np.expand_dims(x, axis=1) = array([[1],\n",
            "       [2],\n",
            "       [3]]), np.expand_dims(x, axis=1).shape = (3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use this to control how x is broadcasted across y:"
      ],
      "metadata": {
        "id": "5SSVja5lz_H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1, 2, 3])\n",
        "y = np.array([[1, 2, 3], [2, 3, 4], [4, 5, 6]])\n",
        "print(f'{x = }, {x.shape = }')\n",
        "print(f'{y = }, {y.shape = }')\n",
        "print(f'{x[None, :] + y = }')\n",
        "print(f'{x[:, None] + y = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIGyDYmQ1XAW",
        "outputId": "d090c784-15a5-4111-e283-5f4c70095328"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([1, 2, 3]), x.shape = (3,)\n",
            "y = array([[1, 2, 3],\n",
            "       [2, 3, 4],\n",
            "       [4, 5, 6]]), y.shape = (3, 3)\n",
            "x[None, :] + y = array([[2, 4, 6],\n",
            "       [3, 5, 7],\n",
            "       [5, 7, 9]])\n",
            "x[:, None] + y = array([[2, 3, 4],\n",
            "       [4, 5, 6],\n",
            "       [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting is pretty commonly used in numpy code, e.g. broadcasting the bias across a batch of features in an linear layer, but can be tricky. Always test your broadcasting code on small examples to make sure it's working correctly!"
      ],
      "metadata": {
        "id": "CG400qCe0KRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's use numpy!\n",
        "Let's use numpy to implement some components commonly used in neural networks! This will introduce us to a few common numpy functions and help us get familiar with the indexing and broadcasting concepts we just read about.\n",
        "\n",
        "Please feel free to look up the expressions on the internet and try implementing these yourself and use the tests to verify your approach before looking at the implementations provided here!"
      ],
      "metadata": {
        "id": "1kQX-pv-NaOk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReLU\n",
        "\n",
        "ReLU (rectified linear unit) is the most basic activation function used in neural networks and is defined as relu(x) = x if x > 0 else 0. Let's implement it in numpy!"
      ],
      "metadata": {
        "id": "pdZGxiU_L0Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return np.where(x > 0, x, 0)"
      ],
      "metadata": {
        "id": "xxCKimteL7A6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it:"
      ],
      "metadata": {
        "id": "4y0lbHx6NC1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tests = 5\n",
        "for _ in range(num_tests):\n",
        "  x = np.random.permutation(np.arange(-5, 5))\n",
        "  print(f'{x = }')\n",
        "  print(f'{relu(x) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0cWXGezNDnG",
        "outputId": "1563dbb2-600c-4e52-c299-100b77341952"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([-3, -4,  0, -5,  3, -2,  4,  1, -1,  2])\n",
            "relu(x) = array([0, 0, 0, 0, 3, 0, 4, 1, 0, 2])\n",
            "x = array([-5,  4, -3,  2,  0,  3,  1, -4, -1, -2])\n",
            "relu(x) = array([0, 4, 0, 2, 0, 3, 1, 0, 0, 0])\n",
            "x = array([ 3, -4, -5, -3,  1,  2,  4, -2, -1,  0])\n",
            "relu(x) = array([3, 0, 0, 0, 1, 2, 4, 0, 0, 0])\n",
            "x = array([ 4,  2, -2,  1, -1, -4,  0,  3, -3, -5])\n",
            "relu(x) = array([4, 2, 0, 1, 0, 0, 0, 3, 0, 0])\n",
            "x = array([ 0, -5,  1,  2, -1, -4,  4, -3,  3, -2])\n",
            "relu(x) = array([0, 0, 1, 2, 0, 0, 4, 0, 3, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also implement relu(x) as `np.maximum(x, 0)`, which returns the element-wise maximum of the two arrays x and 0 (broadcasted). This is different from `np.max(a)` returns the max of array a (optionally, along an axis). Try modifying the implementation and run the tests!\n",
        "\n",
        "BTW, `relu(x) = x[x > 0]` is incorrect. Can you explain why? Modify the function and run the tests to see what happens."
      ],
      "metadata": {
        "id": "AVbcwT5gMZkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid\n",
        "Sigmoid is used to convert the model output (i.e. logit) to a probability, commonly used for binary classfication problems. Let's implement it!"
      ],
      "metadata": {
        "id": "O3T482q6Ly6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "vAwI_XQBOZpu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's harder to inspect correctness, but still, let's run a few tests!"
      ],
      "metadata": {
        "id": "60E6GMmGOnpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tests = 5\n",
        "for _ in range(num_tests):\n",
        "  x = np.random.randn(5)\n",
        "  print(f'{x = }')\n",
        "  print(f'{sigmoid(x) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2NctJQNOfBv",
        "outputId": "fcdb1f99-33f3-49fa-ece1-22fe6b01fd14"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([-0.56682805, -2.24890747,  0.27267574, -1.07624555,  1.39636642])\n",
            "sigmoid(x) = array([0.36196906, 0.09544375, 0.56774968, 0.25421717, 0.80160666])\n",
            "x = array([ 0.41083961, -0.28242042,  0.70086132, -1.52032512, -0.19486307])\n",
            "sigmoid(x) = array([0.60128918, 0.42986048, 0.66837871, 0.17941365, 0.4514378 ])\n",
            "x = array([ 1.07106844, -0.66546428, -1.04139873, -0.34232793, -0.91302592])\n",
            "sigmoid(x) = array([0.74480005, 0.33951321, 0.2608802 , 0.41524411, 0.28638104])\n",
            "x = array([ 1.03158171, -0.02043043, -0.12344788, -1.64196494,  0.99479116])\n",
            "sigmoid(x) = array([0.73722243, 0.49489257, 0.46917716, 0.16219787, 0.73003323])\n",
            "x = array([-0.42999825,  0.46108848,  0.21802558,  0.79601311,  0.00290826])\n",
            "sigmoid(x) = array([0.39412675, 0.61327236, 0.5542915 , 0.689121  , 0.50072706])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One visual check for correctness is that the sigmoid is always positive (can you explain why?). We can also check for correctness using a few known values, e.g. x = 0, x = inf, and x = -inf. Can you explain the following outputs?"
      ],
      "metadata": {
        "id": "vKmyOZPJOv_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  print(f'{sigmoid(0) = }')  # 0.5\n",
        "  print(f'{sigmoid(-np.inf) = }')  # 0.0\n",
        "  print(f'{sigmoid(np.inf) = }')  # 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IrawslmOs29",
        "outputId": "10800ed4-028e-409e-a371-6f9fece2d704"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigmoid(0) = np.float64(0.5)\n",
            "sigmoid(-np.inf) = np.float64(0.0)\n",
            "sigmoid(np.inf) = np.float64(1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax"
      ],
      "metadata": {
        "id": "PaQyaBW5Lt9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x, axis=None):\n",
        "  exp = np.exp(x)\n",
        "  sumexp = np.sum(exp, axis=axis, keepdims=True)\n",
        "  return exp / sumexp"
      ],
      "metadata": {
        "id": "L4MxVEL6Pd_d"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test this before diving into the details:"
      ],
      "metadata": {
        "id": "VipxtFSdSPfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 1], [3, 0]])\n",
        "print(f'{x = }')\n",
        "print(f'{softmax(x) = }')\n",
        "\n",
        "x = np.array([[1, 2], [3, 0]])\n",
        "print(f'{x = }')\n",
        "print(f'{softmax(x, axis=0) = }')\n",
        "\n",
        "x = np.array([[1, 2], [3, 0]])\n",
        "print(f'{x = }')\n",
        "print(f'{softmax(x, axis=1) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Li--jcSMM2",
        "outputId": "ba744197-6818-49fd-9a83-860a3019565e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 1],\n",
            "       [3, 0]])\n",
            "softmax(x) = array([[0.1024912, 0.1024912],\n",
            "       [0.7573132, 0.0377044]])\n",
            "x = array([[1, 2],\n",
            "       [3, 0]])\n",
            "softmax(x, axis=0) = array([[0.11920292, 0.88079708],\n",
            "       [0.88079708, 0.11920292]])\n",
            "x = array([[1, 2],\n",
            "       [3, 0]])\n",
            "softmax(x, axis=1) = array([[0.26894142, 0.73105858],\n",
            "       [0.95257413, 0.04742587]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few things to talk about here, let's break them down step by step.\n",
        "\n",
        "Let's first talk about the axis.\n",
        "\n",
        "Many numpy operations allow you to apply them over one or more (or all) axes of the array. axis=None applies the operation over the entire array. But, commonly you'd apply softmax over a batch of activations (e.g. of shape (B, H), where B is the batch size and H is the hidden dimension) and here you need to apply softmax over each row of features separately rather than the entire array.\n",
        "\n",
        "Compare the examples above:\n",
        "+ #1 applies softmax to the entire array, and so all the values of the softmax add up to 1.\n",
        "+ #2 applies softmax to each column of the array, and so all the values of the softmax in each col add up to 1.\n",
        "+ #3 applies softmax to each row separately, and so all the values of the softmax in each row add up to 1. This is what we want in the (B, H) case.\n",
        "\n",
        "So, axis=k denotes which dimension of the array to apply the operation over. If the shape of the array is (x0, x1, ..., xn), then axis=k applies the operation over the xk dim of the array. In the 2-D case discussed above, axis=0 applies it to the \"batch\" dim (cols), and axis=1 applies it the \"feature\" dim (rows).\n",
        "\n",
        "Let's now talk about `keepdims`.\n",
        "\n",
        "When we apply \"reduce\" operations like sum, max, etc. the number of output dimensions is the number of input dims - the number of axes we applied the operation over. Setting keepdims=True preserves the number of dimensions of the input. For instance, for x of shape (B, H), the output has shape:\n",
        "  + for axis=None (sum over all axes), scalar for keepdims=False, (1, 1) for keepdims=True.\n",
        "  + for axis=0, (H,) for keepdims=False, (1, H) for keepdims=True.\n",
        "  + for axis=1, (B,) for keepdims=False, (B, 1) for keepdims=True.\n",
        "\n",
        "Let's see this in action:"
      ],
      "metadata": {
        "id": "RuGraHTeP2z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 1], [3, 0]])\n",
        "\n",
        "print(f'{x = }, {x.shape = }')\n",
        "for axis in (None, 0, 1):\n",
        "  print(f'{axis = }')\n",
        "  sum_nokeepdim = np.sum(x, axis=axis, keepdims=False)\n",
        "  sum_keepdim = np.sum(x, axis=axis, keepdims=True)\n",
        "  print(f'{np.sum(x, axis=axis, keepdims=False) = }, {sum_nokeepdim.shape = }')\n",
        "  print(f'{np.sum(x, axis=axis, keepdims=True) = }, {sum_keepdim.shape = }')\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmWr8X0MTdmg",
        "outputId": "e0280bd1-f3b6-4d65-ea55-e83503a2f8e7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 1],\n",
            "       [3, 0]]), x.shape = (2, 2)\n",
            "axis = None\n",
            "np.sum(x, axis=axis, keepdims=False) = np.int64(5), sum_nokeepdim.shape = ()\n",
            "np.sum(x, axis=axis, keepdims=True) = array([[5]]), sum_keepdim.shape = (1, 1)\n",
            "axis = 0\n",
            "np.sum(x, axis=axis, keepdims=False) = array([4, 1]), sum_nokeepdim.shape = (2,)\n",
            "np.sum(x, axis=axis, keepdims=True) = array([[4, 1]]), sum_keepdim.shape = (1, 2)\n",
            "axis = 1\n",
            "np.sum(x, axis=axis, keepdims=False) = array([2, 3]), sum_nokeepdim.shape = (2,)\n",
            "np.sum(x, axis=axis, keepdims=True) = array([[2],\n",
            "       [3]]), sum_keepdim.shape = (2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is it important to set keepdims=True? To get the softmax, we divide the exponents of shape (B, H) by the sum of exponents. For axis=None, sumexp is a scalar and trivially broadcasted over shape (B, H). But for axis=0 and axis=1, the shape of sumexp (H,) or (B,) respectively, will be broadcasted over over shape (B, H) and this would fail for axis=1, or worse, if B == H, the sum will be broadcasted over the wrong dim and fail silently. Hence, we guide the broadcasting by setting keepdims=True. BTW, this is equivalent to `sum = np.sum(x, axis=1, keepdims=False); sum = sum[:, None]`\n",
        "\n",
        "\n",
        "Let's check it out with our example (B = H = 2). Can you explain why the answer is wrong with keepdims=False?"
      ],
      "metadata": {
        "id": "3YT6-xHyYj9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1, 1], [3, 0]])\n",
        "\n",
        "print(f'{x = }, {x.shape = }')\n",
        "for axis in (1,):\n",
        "  print(f'{axis = }')\n",
        "  sum_nokeepdim = np.sum(x, axis=axis, keepdims=False)\n",
        "  sum_keepdim = np.sum(x, axis=axis, keepdims=True)\n",
        "  print(f'{np.sum(x, axis=axis, keepdims=False) = }, {sum_nokeepdim.shape = }')\n",
        "  print(f'{np.sum(x, axis=axis, keepdims=True) = }, {sum_keepdim.shape = }')\n",
        "  print(f'Wrong: {x / sum_nokeepdim = }')\n",
        "  print(f'Correct: {x / sum_keepdim = }')\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8umThb9BYjrZ",
        "outputId": "44bec234-c001-4273-b01c-c23a6712980f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[1, 1],\n",
            "       [3, 0]]), x.shape = (2, 2)\n",
            "axis = 1\n",
            "np.sum(x, axis=axis, keepdims=False) = array([2, 3]), sum_nokeepdim.shape = (2,)\n",
            "np.sum(x, axis=axis, keepdims=True) = array([[2],\n",
            "       [3]]), sum_keepdim.shape = (2, 1)\n",
            "Wrong: x / sum_nokeepdim = array([[0.5       , 0.33333333],\n",
            "       [1.5       , 0.        ]])\n",
            "Correct: x / sum_keepdim = array([[0.5, 0.5],\n",
            "       [1. , 0. ]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A general rule of thumb is that numpy can broadcast over the batch dimension, but not others. So (H,) -> (B, H) is correctly done without guidance, but (B,) -> (B, H) has to be guided using res[:, None] (or np.newaxis or np.expand_dims).\n",
        "\n",
        "Great, hopefully your understanding of axes and broadcasting was enriched by this example! Let's apply it to improve the numerical stability of our softmax impl.\n",
        "\n",
        "In our current impl, the sumexp term can become really large. To counter this, we subtract x by the the max of x (along the provided axis) before computing the exponents and summing them. This is equivalent to multiplying both the numerator and denominator of the softmax by exp(-mx) and so has no effect on the output of the softmax. But because the input to exp is now in the range (-inf, 0), the exp will be in range (0, 1) which makes the sumexp manageable.\n",
        "\n",
        "Let's implement this!"
      ],
      "metadata": {
        "id": "G5zxPn3ScScH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stable_softmax(x, axis=None):\n",
        "  mx = np.max(x, axis=axis, keepdims=True)\n",
        "  exps = np.exp(x - mx)\n",
        "  sumexps = np.sum(exps, axis=axis, keepdims=True)\n",
        "  return exps / sumexps"
      ],
      "metadata": {
        "id": "MdGsU3JZdOjd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tests = 5\n",
        "B = 5\n",
        "H = 10\n",
        "for i in range(num_tests):\n",
        "  x = np.random.randn(B, H)\n",
        "  s1 = softmax(x, axis=-1)\n",
        "  s2 = stable_softmax(x, axis=-1)\n",
        "  np.testing.assert_allclose(s1, s2)\n",
        "print(\"The two impls matched!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhykAtrRdZvH",
        "outputId": "0e870258-b8f3-4aa5-d32e-3725a2ec6c78"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The two impls matched!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that as with indexing, `axis=-k` is equivalent to `axis=num_axes-k`. `axis=-1` is often used when you want to apply an operation to the feature dimension but there might be multiple \"batch\" dimensions, e.g. with language models, you often have a batch of token seqeunces of shape (B, T, H). Let's see this in action in LayerNorm!"
      ],
      "metadata": {
        "id": "087kDKL0dpYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LayerNorm"
      ],
      "metadata": {
        "id": "8HIOJg0gLwLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layernorm is a common component of transformer architectures (recently RMSNorm has been more common because it has fewer learnable params, hence simpler).\n",
        "\n",
        "For layernorm, we compute the mean and variance along the feature axis (i.e. for each example in the batch) and normalize the features based on these. We also have 2 learnable params to scale and shift the normalized features; for now we'll assume that these are constants, and we'll later see how to apply backprop and update (i.e. learn) these params. Let's go!"
      ],
      "metadata": {
        "id": "IBUs3blHlGqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def layernorm(x):\n",
        "  B, T, H = x.shape\n",
        "  mean_BT = np.mean(x, axis=-1, keepdims=True)\n",
        "  var_BT = np.var(x, axis=-1, keepdims=True)\n",
        "  eps = 1e-8\n",
        "  norm_x_BTH = (x - mean_BT) / np.sqrt(var_BT + eps)\n",
        "  # learnable params\n",
        "  scale_H = np.ones((H,))\n",
        "  shift_H = np.zeros((H,))\n",
        "  return norm_x_BTH * scale_H + shift_H"
      ],
      "metadata": {
        "id": "swZtpu8mLtO5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test this! Again, it's hard to visually inspect for correctness, but let's create an input array of large numbers so that we can see the effect of normalization (i.e. output values are close to 0). In our impl, the scale (= 1) and shift (= 0) have no effect because we're multiplying by 1 and shifting by 0."
      ],
      "metadata": {
        "id": "BAfhrz90rTRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B = 2\n",
        "T = 3\n",
        "H = 4\n",
        "\n",
        "x = np.random.randn(B, T, H)\n",
        "# scale and shift by large numbers so that we can see the effect of layernorm\n",
        "x = x * 100 + 200\n",
        "print(f'{x = }')\n",
        "print(f'{layernorm(x) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2duR4bSBmQ4t",
        "outputId": "eeef6184-86c5-4b6e-eb0c-0d25de070eb0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[[357.79169561, 208.15738989, 111.13551003, 153.71720507],\n",
            "        [105.66080791, 162.39187008, 172.84249259,  87.72740474],\n",
            "        [241.95510612, 120.82886376, 203.76837997, 202.8443505 ]],\n",
            "\n",
            "       [[ 17.87137652, 263.96670787, 328.09823822, 201.05003962],\n",
            "        [221.92099606, 220.7273338 , 368.30185166,   2.22508811],\n",
            "        [213.29101514, 167.96342076, 221.96545766, 156.90834108]]])\n",
            "layernorm(x) = array([[[ 1.60992053,  0.00490126, -1.03578246, -0.57903933],\n",
            "        [-0.73164101,  0.83495754,  1.12354601, -1.22686254],\n",
            "        [ 1.12217042, -1.61791092,  0.25832181,  0.23741869]],\n",
            "\n",
            "       [[-1.59644341,  0.52865092,  1.08244262, -0.01465014],\n",
            "        [ 0.14254234,  0.13340798,  1.26270498, -1.5386553 ],\n",
            "        [ 0.82949729, -0.78704629,  1.13885883, -1.18130984]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember our rule of thumb regarding broadcasting: numpy knows how to broadcast over the batch dim. Hence we use keepdims=True to guide the broadcasting of mean and var because these are broadcasted over the feature dim (axis=2 or axis=-1), but we don't need to guide the broadcasting of the scale and shift params which are broadcasted over the batch dims. Hence `norm_x_BTH * scale_H[None, None, :] + shift_H[None, None, :]` is redundant."
      ],
      "metadata": {
        "id": "_AAWzqoyqlzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication"
      ],
      "metadata": {
        "id": "knZTfJO-1UEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're rusty on matrix multiplication, do a quick google search and familiarize yourself with the concept.\n",
        "\n",
        "Let's look a few common matrix multiplications we'll encounter in practice.\n",
        "\n",
        "One is projecting a batch of activations from one dimension (e.g. model dimension) to another (e.g. hidden dimensions). This involves multiplying an activations array of shape B, F and a (learnable) weight array of shape F, H (B -> batch dim, F -> feature dim, H -> hidden dim) to get an activations array of shape B, H. Let's implement this in 4 ways!"
      ],
      "metadata": {
        "id": "ZH6T7lZ911vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B, F, H = 2, 3, 4\n",
        "x = np.random.randn(B, F)\n",
        "y = np.random.randn(F, H)\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "\n",
        "print(f'{np.dot(x, y) = }')\n",
        "print(f'{np.matmul(x, y) = }')\n",
        "print(f'{x@y = }')\n",
        "print(f'{np.einsum(\"bf,fh->bh\", x, y) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P_AaE3O1WWP",
        "outputId": "be07b767-6e11-46dd-9ecd-f3249b2c5362"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[-0.63207154,  1.63526704,  1.05375833],\n",
            "       [ 0.82515517, -1.80175095,  0.61887486]])\n",
            "y = array([[-0.56440053, -0.18720503,  0.22760663, -0.62886488],\n",
            "       [ 0.93584682,  0.84739081, -0.08651255,  0.19707451],\n",
            "       [-0.60932031, -0.05660355,  0.32302553,  0.27083101]])\n",
            "np.dot(x, y) = array([[ 1.24502461,  1.44439077,  0.05505604,  1.00514748],\n",
            "       [-2.52897394, -1.71629091,  0.54359724, -0.70637979]])\n",
            "np.matmul(x, y) = array([[ 1.24502461,  1.44439077,  0.05505604,  1.00514748],\n",
            "       [-2.52897394, -1.71629091,  0.54359724, -0.70637979]])\n",
            "x@y = array([[ 1.24502461,  1.44439077,  0.05505604,  1.00514748],\n",
            "       [-2.52897394, -1.71629091,  0.54359724, -0.70637979]])\n",
            "np.einsum(\"bf,fh->bh\", x, y) = array([[ 1.24502461,  1.44439077,  0.05505604,  1.00514748],\n",
            "       [-2.52897394, -1.71629091,  0.54359724, -0.70637979]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another scenario is projecting a batch of activations from the feature dimension to a scalar for a binary classifier. This involves multiplying an activations array of shape B, F and a (learnable) weight array of shape F to get an activations array of shape (B,). This is generally passed through sigmoid to get a batch of probabilities. Let's implement this in 4 ways!"
      ],
      "metadata": {
        "id": "MONwhu0JLMZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B, F = 2, 3\n",
        "x = np.random.randn(B, F)\n",
        "y = np.random.randn(F)\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "\n",
        "print(f'{np.dot(x, y) = }')\n",
        "print(f'{np.matmul(x, y) = }')\n",
        "print(f'{x@y = }')\n",
        "print(f'{np.einsum(\"bf,f->b\", x, y) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32PtvmUZTw4V",
        "outputId": "82c820e5-288f-44a0-8a6c-6832178bd74e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = array([[ 1.29142654,  0.76313607, -0.16906432],\n",
            "       [ 0.37681326, -1.39252537,  1.08533761]])\n",
            "y = array([-0.27512246,  0.57937015,  1.1045357 ])\n",
            "np.dot(x, y) = array([-0.09989978,  0.28833671])\n",
            "np.matmul(x, y) = array([-0.09989978,  0.28833671])\n",
            "x@y = array([-0.09989978,  0.28833671])\n",
            "np.einsum(\"bf,f->b\", x, y) = array([-0.09989978,  0.28833671])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look an example with more dimensions. In language models, we multiply a batch of token activations of shape (B, T, F) with a (learned) multi-headed query projection matrix of shape (N, F, H) to get a batch of multi-headed queries of shape (B, T, N, H) where (B is batch dim, T is the sequence length, F is the feature dim, N is the number of query heads and H is the attention dim). Let's implement this!"
      ],
      "metadata": {
        "id": "GWKpS_BgUBXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B, F = 2, 3\n",
        "x = np.random.randn(B, F)\n",
        "y = np.random.randn(F)\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "\n",
        "print(f'{np.dot(x, y) = }')\n",
        "print(f'{np.matmul(x, y) = }')\n",
        "print(f'{x@y = }')\n",
        "print(f'{np.einsum(\"bf,f->b\", x, y) = }')"
      ],
      "metadata": {
        "id": "MUreeWjtUBEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at 2-D arrays. In the 2-D case"
      ],
      "metadata": {
        "id": "aXgYNdBk3bql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.einsum uses Einstein summation convention to denote the operation. commonly describes the input shapes and the output shapes, denoting the batch, contracting and non-contracting dimensions. Batch dimensions appear in both inputs and the output, non-contracting dimensions appear in one of the inputs and the output, contracting dimensions appear in both inputs but not in the output."
      ],
      "metadata": {
        "id": "15tQMu4f2N0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.permutation(4)\n",
        "y = np.random.permutation(5)\n",
        "print(f'{x = }')\n",
        "print(f'{y = }')\n",
        "print(f'{np.dot(x[:, None], y[None, :]) = }')\n",
        "print(f'{np.linalg.matmul(x[:, None], y[None, :]) = }')"
      ],
      "metadata": {
        "id": "5-hDv1xo4cFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{np.einsum(\"n,n->\", x, y) = }')"
      ],
      "metadata": {
        "id": "QRGzwOJ53ZFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}